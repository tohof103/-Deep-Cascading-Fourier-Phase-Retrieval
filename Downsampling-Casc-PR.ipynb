{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "from fourier import fft2WoSq, magnitude, squaredmagnitude, fft2\n",
    "from pics import downsamplingsaveToPDF, plot_grid\n",
    "from tests import downsampling_test\n",
    "from models import DCSigmoidNet, ConvNet\n",
    "from loader import load\n",
    "torch.manual_seed(17)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(new, Net, NUM_Of_Nets, im_size, netsizes, channels, device, lr, dataset):\n",
    "    '''\n",
    "    Initializes/loads networks and optimizer\n",
    "    Parameters:\n",
    "    -----------\n",
    "        new: boolean\n",
    "            Create new network or use previous if existing\n",
    "        Net: nn.module class\n",
    "            Class of network to be used\n",
    "        NUM_Of_Nets: int\n",
    "            Number of networks\n",
    "        im_size: int array\n",
    "            Array of reconstruction sizes\n",
    "        netsizes: int array\n",
    "            Sizes of fully connected layers of networks\n",
    "        channels: int\n",
    "            Number of color channels\n",
    "        device: torch.device\n",
    "            Device to initialize the networks to\n",
    "        lr: int\n",
    "            Learning rate for optimizer\n",
    "        dataset: string\n",
    "            Name of dataset to load old network\n",
    "    Returns:\n",
    "    --------\n",
    "        nets: nn.module array\n",
    "        optimizer: torch.optim\n",
    "    '''\n",
    "    nets = []\n",
    "    optimizer = []\n",
    "    for i in range(NUM_Of_Nets):\n",
    "        if os.path.isfile('Nets/{}/CasPR{}{}.pt'.format(dataset, netsizes[i], i)):\n",
    "            if(new):\n",
    "                os.remove('Nets/{}/CasPR{}{}.pt'.format(dataset, netsizes[i], i))\n",
    "                print('deleted old Net')\n",
    "                if i == 0:\n",
    "                    nets.append(Net(imsize=(channels, im_size[-1], im_size[-1]),\n",
    "                                    outsize=(channels, im_size[i], im_size[i]),\n",
    "                                    h = netsizes[i]))\n",
    "                else:\n",
    "                    nets.append(Net(imsize=(channels*2, im_size[-1], im_size[-1]),\n",
    "                                    outsize=(channels, im_size[i], im_size[i]),\n",
    "                                    h = netsizes[i]))\n",
    "            else:\n",
    "                print('loaded previous Net')\n",
    "                nets.append(torch.load('Nets/{}/CasPR{}{}.pt'.format(dataset, netsizes[i], i)))\n",
    "        else:\n",
    "            if i == 0:\n",
    "                nets.append(Net(imsize=(channels, im_size[-1], im_size[-1]),\n",
    "                                outsize=(channels, im_size[i], im_size[i]),\n",
    "                                h = netsizes[i]))\n",
    "            else:\n",
    "                nets.append(Net(imsize=(channels*2, im_size[-1], im_size[-1]),\n",
    "                                outsize=(channels, im_size[i], im_size[i]),\n",
    "                                h = netsizes[i]))\n",
    "                \n",
    "        nets[i] = nets[i].to(device)        \n",
    "        optimizer.append(optim.Adam(nets[i].parameters(), lr = lr))        \n",
    "    return nets, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, NUM_Of_Nets, device, im_size, tau, nets, optimizer, losses, train_data):\n",
    "    '''\n",
    "    Trains networks for one epoch\n",
    "    Parameters:\n",
    "    -----------\n",
    "        epoch: int\n",
    "            Current epoch number\n",
    "        NUM_Of_Nets: int\n",
    "            Number of networks\n",
    "        device: torch.device\n",
    "            Device to train on            \n",
    "        im_size: int array\n",
    "            Array of reconstruction sizes\n",
    "        nets: nn.module array\n",
    "            Array of networks to train\n",
    "        optimizer: torch.optim array\n",
    "            Array of optimizer for training\n",
    "        losses: (loss-)function array\n",
    "            Array of losses used to train each network\n",
    "        train_data: dataloader\n",
    "            Dataloader of training data        \n",
    "    Returns:\n",
    "    --------\n",
    "        -\n",
    "    '''\n",
    "    for net in nets:\n",
    "        net.train()\n",
    "    \n",
    "    tot_loss = 0\n",
    "    reg_loss = 0\n",
    "        \n",
    "    for target in train_data:\n",
    "        target = target.to(device)\n",
    "        \n",
    "        for step in range(NUM_Of_Nets):\n",
    "            stage_target = F.interpolate(target, size=(im_size[step],im_size[step]))\n",
    "            data = magnitude(fft2WoSq(target)).to(device)\n",
    "            if step > 0:\n",
    "                out = F.interpolate(out, size=(im_size[-1], im_size[-1]))\n",
    "                data = torch.cat([data, out], 1)\n",
    "                \n",
    "            optimizer[step].zero_grad()    \n",
    "            data = data.detach()\n",
    "            out = nets[step](data)\n",
    "            \n",
    "            criterion = losses[step]\n",
    "            loss = criterion(out, stage_target)\n",
    "            \n",
    "            if tau > 0:\n",
    "                mags = squaredmagnitude(fft2(stage_target))\n",
    "                mags = mags.detach()\n",
    "                reg = tau*torch.mean((squaredmagnitude(fft2(out))-mags)**2)\n",
    "                loss = loss + reg\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer[step].step()\n",
    "    \n",
    "        tot_loss = tot_loss + loss.item()\n",
    "    print('Epoche: {:3.0f} | Loss: {:.6f}'.format(epoch, tot_loss/len(train_data)))\n",
    "\n",
    "def train(NUM_Of_Nets, device, im_size, tau, nets, optimizer, losses, data, num_epochs):\n",
    "    '''\n",
    "    Trains networks for given number of epochs\n",
    "    Parameters:\n",
    "    -----------\n",
    "        NUM_Of_Nets: int\n",
    "            Number of networks\n",
    "        device: torch.device\n",
    "            Device to train on\n",
    "        im_size: int array\n",
    "            Array of reconstruction sizes\n",
    "        nets: nn.module array\n",
    "            Array of networks to train\n",
    "        optimizer: torch.optim array\n",
    "            Array of optimizer for training\n",
    "        losses: (loss-)function array\n",
    "            Array of losses used to train each network\n",
    "        data: dataloader array\n",
    "            Dataloader of dataset data \n",
    "        num_epochs: int\n",
    "            Number of epochs to train\n",
    "    Returns:\n",
    "    --------\n",
    "        -\n",
    "    '''\n",
    "    train_data = data['train']\n",
    "    val_data = data['val']\n",
    "    times = np.empty(0)\n",
    "    print(\"=======================================\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_proc = time.process_time()\n",
    "        train_epoch(epoch, NUM_Of_Nets, device, im_size, tau, nets, optimizer, losses, train_data)\n",
    "        ende_proc = time.process_time()\n",
    "        times = np.append(times, ende_proc-start_proc)\n",
    "        if epoch % 20 == 0:\n",
    "            downsampling_test(nets, val_data, NUM_Of_Nets, device, im_size, True, False)\n",
    "    print(times.mean())\n",
    "    print(times.max())\n",
    "    print(times.min())\n",
    "    print(times.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = False\n",
    "save = False\n",
    "dataset = 'mnist'\n",
    "Net = DCSigmoidNet     #ConvNet for CelebA, DCSigmoidNet for (fashion-)MNIST\n",
    "Num_Of_Nets = 5\n",
    "device = torch.device(\"cuda:1\")\n",
    "netsizes = [1100, 1300, 1500, 1800, 1800]\n",
    "lr = 0.0001\n",
    "im_size = [7,14,21,28,28]    #For (fashion-)MNIST\n",
    "#im_size = [16,32,48,64,64]   #For CelebA\n",
    "tau = 0#2e-4\n",
    "losses = [nn.MSELoss(), nn.MSELoss(), nn.MSELoss(), nn.MSELoss(), nn.MSELoss()]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing, training and possible saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targetsize = load(name = dataset)                            #For (fashion-)MNIST\n",
    "#data, targetsize = load(name = 'celeba', path=\"CelebA/CelebA.h5\")   #For CelebA\n",
    "nets, optimizer = init(new, Net, Num_Of_Nets, im_size, netsizes, targetsize[0], device, lr, dataset) \n",
    "\n",
    "start_proc = time.process_time()\n",
    "train(Num_Of_Nets, device, im_size, tau, nets, optimizer, losses, data, num_epochs = 100)    \n",
    "ende_proc = time.process_time()\n",
    "print('Systemzeit: {:5.3f}s'.format(ende_proc-start_proc))\n",
    "\n",
    "if save:\n",
    "    for i in range(Num_Of_Nets):\n",
    "        torch.save(nets[i], 'Nets/{}/CasPR{}{}.pt'.format(dataset, netsizes[i], i))\n",
    "        print('CasPR{}{} saved'.format(netsizes[i], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests and print to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data['test']\n",
    "val_data = data['val']\n",
    "start_proc = time.process_time()\n",
    "downsampling_test(nets, test_data, Num_Of_Nets, device, im_size, pics = True, save = False)\n",
    "ende_proc = time.process_time()\n",
    "print('Systemzeit: {:5.3f}s'.format(ende_proc-start_proc))\n",
    "#downsamplingsaveToPDF(nets, test_data, Num_Of_Nets, device, im_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
